{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.chains.graph_qa.neptune_sparql import NeptuneSparqlQAChain\n",
    "\n",
    "from neo4j import Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "from botocore.credentials import Credentials\n",
    "from botocore.auth import (\n",
    "  SigV4Auth,\n",
    "  _host_from_url,\n",
    ")\n",
    "\n",
    "SCHEME = \"basic\"\n",
    "REALM = \"realm\"\n",
    "SERVICE_NAME = \"neptune-db\"\n",
    "DUMMY_USERNAME = \"username\"\n",
    "HTTP_METHOD_HDR = \"HttpMethod\"\n",
    "HTTP_METHOD = \"GET\"\n",
    "AUTHORIZATION = \"Authorization\"\n",
    "X_AMZ_DATE = \"X-Amz-Date\"\n",
    "X_AMZ_SECURITY_TOKEN = \"X-Amz-Security-Token\"\n",
    "HOST = \"Host\"\n",
    "\n",
    "\n",
    "class NeptuneAuthToken(Auth):\n",
    "  def __init__(\n",
    "    self,\n",
    "    credentials: Credentials,\n",
    "    region: str,\n",
    "    url: str,\n",
    "    **parameters\n",
    "  ):\n",
    "    # Do NOT add \"/opencypher\" in the line below if you're using an engine version older than 1.2.0.0\n",
    "    request = AWSRequest(method=HTTP_METHOD, url=url + \"/opencypher\")\n",
    "    request.headers.add_header(\"Host\", _host_from_url(request.url))\n",
    "    sigv4 = SigV4Auth(credentials, SERVICE_NAME, region)\n",
    "    sigv4.add_auth(request)\n",
    "\n",
    "    auth_obj = {\n",
    "      hdr: request.headers[hdr]\n",
    "      for hdr in [AUTHORIZATION, X_AMZ_DATE, X_AMZ_SECURITY_TOKEN, HOST]\n",
    "    }\n",
    "    auth_obj[HTTP_METHOD_HDR] = request.method\n",
    "    creds: str = json.dumps(auth_obj)\n",
    "    super().__init__(SCHEME, DUMMY_USERNAME, creds, REALM, **parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bolt://neptune.geoprism.net:8182/opencypher\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "# importing os module for environment variables\n",
    "import os\n",
    "# importing necessary functions from dotenv library\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "# loading variables from .env file\n",
    "load_dotenv() \n",
    "\n",
    "aws_access_key_id=os.getenv('AWS_KEY_ID'),\n",
    "aws_secret_access_key=os.getenv('AWS_SECRET_KEY'),\n",
    "url = os.getenv('AWS_NEPTUNE_URL')\n",
    "region = os.getenv('AWS_REGION')\n",
    "\n",
    "# credentials = Credentials(access_key=aws_access_key_id[0], secret_key=aws_secret_access_key[0])\n",
    "# authToken = NeptuneAuthToken(credentials, region , url)\n",
    "# driver = GraphDatabase.driver(url, auth=authToken, encrypted=True)\n",
    "\n",
    "print(url)\n",
    "\n",
    "driver = GraphDatabase.driver(url, auth=(\"username\", \"password\"), encrypted=True, trust='TRUST_ALL_CERTIFICATES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query failed: Couldn't connect to neptune.geoprism.net:8182 (resolved to ()):\n",
      "Connection to 44.225.75.201:8182 closed without handshake response\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# importing os module for environment variables\n",
    "import os\n",
    "# importing necessary functions from dotenv library\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "# loading variables from .env file\n",
    "load_dotenv() \n",
    "\n",
    "from classes import Neo4jConnection\n",
    "from rdflib import Dataset\n",
    "from rdflib.namespace import RDF\n",
    "\n",
    "conn = Neo4jConnection(driver)\n",
    "\n",
    "try:\n",
    "    res = conn.query(\"MATCH (n) RETURN n LIMIT 1\")\n",
    "\n",
    "    # # Clean the database\n",
    "    # # res = conn.query(f\"match (a) -[r] -> () delete a, r\")\n",
    "    # # res = conn.query(f\"match (a) delete a\")\n",
    "    # # res = conn.query(f\"DROP INDEX entities IF EXISTS\")\n",
    "    # # res = conn.query(f\"DROP INDEX entity_index IF EXISTS\")\n",
    "\n",
    "    # dataset = Dataset()\n",
    "    # dataset.parse(\"data/model.trig\", \"format=trig\")\n",
    "\n",
    "    # # @prefix geo: <http://www.opengis.net/ont/geosparql#> .\n",
    "    # # @prefix lpgv: <https://dev-georegistry.geoprism.net/lpg/deliverable2024/0#> .\n",
    "    # # @prefix lpg: <https://dev-georegistry.geoprism.net/lpg#> .\n",
    "    # # @prefix lpgs: <https://dev-georegistry.geoprism.net/lpg/rdfs#> .\n",
    "    # # @prefix sf: <http://www.opengis.net/ont/sf#> .\n",
    "    # # @prefix lpgvs: <https://dev-georegistry.geoprism.net/lpg/deliverable2024/0/rdfs#> .\n",
    "    # # @prefix dcterms: <http://purl.org/dc/terms/> .\n",
    "    # # @prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
    "\n",
    "    # school_query = \"\"\"\n",
    "    # PREFIX lpgvs: <https://dev-georegistry.geoprism.net/lpg/deliverable2024/0/rdfs#>\n",
    "    # PREFIX lpgs: <https://dev-georegistry.geoprism.net/lpg/rdfs#>\n",
    "    # PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "\n",
    "    # SELECT ?schoolCode ?schoolLabel ?zoneCode ?zoneLabel ?areaCode ?areaLabel ?leveeCode ?leveeLabel ?channelCode ?channelLabel\n",
    "    # WHERE {\n",
    "    #     ?school a lpgvs:School .\n",
    "    #     ?school lpgs:GeoObject-code ?schoolCode .\n",
    "    #     ?school rdfs:label ?schoolLabel .   \n",
    "    #     ?school lpgvs:HasSchoolZone ?zone .\n",
    "    #     ?school lpgvs:HasFloodRisk ?area .    \n",
    "    #     ?area lpgvs:HasFloodZone ?levee .\n",
    "    #     ?levee lpgvs:HasFloodZone ?channel .        \n",
    "    #     ?zone lpgs:GeoObject-code ?zoneCode .\n",
    "    #     ?zone rdfs:label ?zoneLabel .      \n",
    "    #     ?area lpgs:GeoObject-code ?areaCode .\n",
    "    #     ?area rdfs:label ?areaLabel .   \n",
    "    #     ?levee lpgs:GeoObject-code ?leveeCode .\n",
    "    #     ?levee rdfs:label ?leveeLabel .           \n",
    "    #     ?channel lpgs:GeoObject-code ?channelCode .\n",
    "    #     ?channel rdfs:label ?channelLabel .           \n",
    "    # }\n",
    "    # LIMIT 1\n",
    "    # \"\"\"\n",
    "\n",
    "    # for c in dataset.graphs():  # doctest: +SKIP\n",
    "    #     if 'deliverable2024' in str(c.identifier):\n",
    "        \n",
    "    #         qres = c.query(school_query)\n",
    "    \n",
    "    #         for row in qres:\n",
    "                \n",
    "    #             schoolLabel = row.schoolLabel.replace(\"'\", \"\\\\'\")\n",
    "    #             zoneLabel = row.zoneLabel.replace(\"'\", \"\\\\'\")\n",
    "    #             areaLabel = row.areaLabel.replace(\"'\", \"\\\\'\")\n",
    "    #             leveeLabel = row.leveeLabel.replace(\"'\", \"\\\\'\")\n",
    "    #             channelLabel = row.channelLabel.replace(\"'\", \"\\\\'\")\n",
    "            \n",
    "    #             statement = (\n",
    "    #                 f\"MERGE (area:Entity:FloodArea {{name: '{areaLabel}', code: '{row.areaCode}'}})\"\n",
    "    #                 f\"MERGE (school:Entity:School {{name: '{schoolLabel}', code: '{row.schoolCode}'}})\"\n",
    "    #                 f\"MERGE (zone:Entity:SchoolZone {{name: '{zoneLabel}', code: '{row.zoneCode}'}})\"                \n",
    "    #                 f\"MERGE (levee:Entity:Levee {{name: '{leveeLabel}', code: '{row.leveeCode}'}})\"                                    \n",
    "    #                 f\"MERGE (channel:Entity:Channel {{name: '{channelLabel}', code: '{row.channelCode}'}})\"                                                        \n",
    "    #                 f\"MERGE (zone)-[:HAS_SCHOOL]->(school)\"\n",
    "    #                 f\"MERGE (school)-[:HAS_FLOOD_AREA]->(area)\"                \n",
    "    #                 f\"MERGE (area)-[:PROTECTED_BY]->(levee)\"                                    \n",
    "    #                 f\"MERGE (levee)-[:PROTECTS_AGAINST]->(channel)\"                                                        \n",
    "    #             )\n",
    "                \n",
    "    #             print(statement)\n",
    "            \n",
    "    # #             res = conn.query(statement)\n",
    "            \n",
    "    # # conn.query(\"CREATE FULLTEXT INDEX entities FOR (n:Entity) ON EACH [n.name]\")\n",
    "finally:\n",
    "    print('done')\n",
    "    # conn.close()       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
