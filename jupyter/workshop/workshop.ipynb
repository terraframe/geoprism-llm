{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv(\"app.properties\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "============================================================================\n",
    "\n",
    "Build the graph from geojson feature data\n",
    "\n",
    "============================================================================\n",
    "\"\"\"\n",
    "import fiona\n",
    "from shapely import within, overlaps, dwithin\n",
    "from shapely.geometry import shape\n",
    "from rdflib import Dataset, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "\"\"\"\n",
    "Define the in-memory graph\n",
    "\"\"\"\n",
    "# Define a namespace\n",
    "NAMESPACE = Namespace(\"https://terraframe.com/example/graph\")\n",
    "\n",
    "# Create a QUAD dataset\n",
    "dataset = Dataset()\n",
    "# Add a triple graph to the dataset\n",
    "graph = dataset.graph(URIRef(NAMESPACE + \"#\"))\n",
    "\n",
    "\n",
    "# Create metadata about the types we want to define in the graph including: \n",
    "#   Name of type\n",
    "#   The location of the data\n",
    "#   Any extra feature properties we want to create triples for\n",
    "channelType = {'type':'ChannelReach',\"location\": \"data/geojson/ChannelReach.geojson\", 'props':[]}\n",
    "leveeType = {'type':'LeveeArea',\"location\": \"data/geojson/LeveeArea.geojson\", 'props':[]}\n",
    "areaType = {'type':'LeveedArea',\"location\": \"data/geojson/LeveedArea.geojson\", 'props':[]}\n",
    "tractType = {'type':'CensusTract',\"location\": \"data/geojson/CensusTract.geojson\", 'props':[{'name': 'population', 'target':\"CensusTract-population\", 'type': 'integer'}]}\n",
    "zoneType = {'type':'SchoolZone',\"location\": \"data/geojson/SchoolZone.geojson\", 'props':[]}\n",
    "schoolType = {'type':'School', \"location\": \"data/geojson/School.geojson\", 'props':[{'name': 'population', 'target':\"School-population\", 'type': 'integer'}]}\n",
    "\n",
    "# List of type metadata to process\n",
    "nodes = [channelType, leveeType, areaType, tractType, zoneType, schoolType]\n",
    "\n",
    "# Define metadata about the edge types we want to define including:\n",
    "#   Name of edge\n",
    "#   Function to use to determine if an edge should be create between two features\n",
    "#   List of source feature types to use\n",
    "#   List of target feature types to use\n",
    "edges = [\n",
    "    {'type': 'HasFloodRisk', 'function': 'WITHIN', 'sources': [areaType], 'targets': [schoolType]},\n",
    "    {'type': 'HasFloodZone', 'function': 'OVERLAPS', 'sources': [leveeType], 'targets': [areaType]},    \n",
    "    {'type': 'HasSchoolZone', 'function': 'WITHIN', 'sources': [zoneType], 'targets': [schoolType]},        \n",
    "    {'type': 'ChannelHasLevee', 'function': 'DISTANCE', 'sources': [channelType], 'targets': [leveeType]},        \n",
    "    {'type': 'TractAtRisk', 'function': 'OVERLAPS', 'sources': [tractType], 'targets': [areaType]},            \n",
    "]\n",
    "\n",
    "# Create the attribute triples and add them to the graph\n",
    "for nodeType in nodes:\n",
    "    \n",
    "    # Load the features into memory\n",
    "    features = fiona.open(nodeType['location'], \"r\")\n",
    "    \n",
    "    for feature in features:    \n",
    "        \n",
    "        # Define the URI for the feature and type\n",
    "        id = URIRef(NAMESPACE + \"#\" + nodeType['type'] + '-' + feature['properties']['code'])        \n",
    "        type = URIRef(NAMESPACE + \"#\" + nodeType['type'])\n",
    "        \n",
    "        # Create the code attribute  triple for the feature\n",
    "        graph.add((id, URIRef(NAMESPACE + \"#code\"), Literal(feature['properties']['code'])))\n",
    "\n",
    "        # Create the label attribute triple for the feature        \n",
    "        graph.add((id, RDFS.label, Literal(feature['properties']['label'])))\n",
    "        \n",
    "        # Create the type triple for the feature                \n",
    "        graph.add((id, RDF.type, type))\n",
    "        \n",
    "        #\n",
    "        # Process the extra feature properties defined in the\n",
    "        # type metadata and create attribute triples for them\n",
    "        #\n",
    "        for prop in nodeType['props']:\n",
    "            name = URIRef(NAMESPACE + \"#\" + prop['target'])\n",
    "            \n",
    "            value = str(feature['properties'][prop['name']])\n",
    "            datatype = XSD.int if prop['type'] == 'integer' else XSD.string   \n",
    "            \n",
    "            graph.add((id, name, Literal(value, datatype=datatype)))\n",
    "            \n",
    "    features.close()\n",
    "\n",
    "\"\"\"\n",
    "============================================================================\n",
    "\n",
    "Compute the edges and add them as triples\n",
    "\n",
    "============================================================================\n",
    "\"\"\"\n",
    "for edge in edges:\n",
    "    \n",
    "    # Define the URI of the edge type\n",
    "    type = URIRef(NAMESPACE + \"#\" + edge['type'])\n",
    "    \n",
    "    for sourceType in edge['sources']:\n",
    "        sourceFeatures = fiona.open(sourceType['location'], \"r\")\n",
    "        \n",
    "        for targetType in edge['targets']:\n",
    "            targetFeatures = fiona.open(targetType['location'], \"r\")\n",
    "            \n",
    "            # Loop through all of the source features\n",
    "            for sourceFeature in sourceFeatures:    \n",
    "                \n",
    "                # Convert the geometry to a Shapely geometry\n",
    "                sourceGeom = shape(sourceFeature['geometry'])  \n",
    "                \n",
    "                # Define the source feature URI\n",
    "                sourceId = URIRef(NAMESPACE + \"#\" + sourceType['type'] + '-' + sourceFeature['properties']['code'])\n",
    "                \n",
    "                # Loop through all of the target features\n",
    "                for targetFeature in targetFeatures:\n",
    "                    # Convert the target feature to a geometry\n",
    "                    targetGeom = shape(targetFeature['geometry'])\n",
    "                    \n",
    "                    # Define the target feature URI\n",
    "                    targetId = URIRef(NAMESPACE + \"#\" + targetType['type'] + '-' + targetFeature['properties']['code'])\n",
    "                    \n",
    "                    # \n",
    "                    # Based on the edge metadata function determine if an edge should\n",
    "                    # be created between the two features\n",
    "                    #\n",
    "                    if edge['function'] == 'WITHIN' and within(targetGeom, sourceGeom):\n",
    "                        graph.add((sourceId, type, targetId))                       \n",
    "                    elif edge['function'] == 'OVERLAPS' and overlaps(targetGeom, sourceGeom):\n",
    "                        graph.add((sourceId, type, targetId))                                               \n",
    "                    elif edge['function'] == 'DISTANCE' and dwithin(targetGeom, sourceGeom, 100):\n",
    "                        graph.add((sourceId, type, targetId))                       \n",
    "        \n",
    "            targetFeatures.close()        \n",
    "        \n",
    "        sourceFeatures.close()\n",
    "        \n",
    "\"\"\" \n",
    "Hard-coded edges generated from outside analytics tool\n",
    "\"\"\"\n",
    "type = URIRef(NAMESPACE + \"#FlowsInto\")\n",
    "\n",
    "graph.add(( URIRef(NAMESPACE + \"#ChannelReach-CEMVK_RR_03_ONE_28\"  ), type, URIRef(NAMESPACE + \"#ChannelReach-CEMVK_RR_03_ONE_27\"  )))                       \n",
    "graph.add(( URIRef(NAMESPACE + \"#ChannelReach-CEMVK_RR_03_ONE_27\"  ), type, URIRef(NAMESPACE + \"#ChannelReach-CEMVK_RR_03_ONE_26\"  )))                       \n",
    "graph.add(( URIRef(NAMESPACE + \"#ChannelReach-CEMVK_RR_03_ONE_26\"  ), type, URIRef(NAMESPACE + \"#ChannelReach-CEMVK_RR_03_ONE_25\"  )))                       \n",
    "\n",
    "\"\"\" \n",
    "Export the graph to a file\n",
    "\"\"\"\n",
    "print(dataset.serialize(format=\"trig\"), file=open('data/export.trig', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# JSON specific for the tool to be provided to Bedrock\n",
    "def get_tool_spec():\n",
    "    \"\"\"\n",
    "    Returns the JSON Schema specification for the SPARQL tool. The tool specification\n",
    "    defines the input schema and describes the tool's functionality.\n",
    "    For more information, see https://json-schema.org/understanding-json-schema/reference.\n",
    "\n",
    "    :return: The tool specification for the SPARQL tool.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"toolSpec\": {\n",
    "            \"name\": \"Sparql_Tool\",\n",
    "            \"description\": \"Get a result set from a triple store, based on a SPARQL select statement.\",\n",
    "            \"inputSchema\": {\n",
    "                \"json\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"statement\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"SPARQL select statement.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"statement\"],\n",
    "                }\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Implementation of the tool which executes SPARQL on the in-memory dataset\n",
    "def exectue_sparql(input_data):\n",
    "    \"\"\"\n",
    "    Executes a SPARQL statement from in an memory graphstore.\n",
    "    Returns a JSON array of the results.\n",
    "\n",
    "    :param input_data: The input data containing the SPARQL select statement.\n",
    "    :return: The .\n",
    "    \"\"\"\n",
    "    statement = input_data.get(\"statement\")\n",
    "\n",
    "    try:\n",
    "        qres = dataset.query(statement)\n",
    "    \n",
    "        rows = []\n",
    "        for row in qres:\n",
    "            data = {}\n",
    "        \n",
    "            for var in qres.vars:\n",
    "                data[str(var)] = str(row.get(var, \"\"))\n",
    "            \n",
    "            rows.append(data)\n",
    "        \n",
    "        return rows\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": type(e), \"message\": str(e)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the SPARQL tool\n",
    "statement = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\t\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "\n",
    "SELECT (SUM(?population) as ?totalPopulation)\t\n",
    "FROM <https://terraframe.com/example/graph#>\n",
    "WHERE {\n",
    "  ?censusTract obj:CensusTract-population ?population .\t\n",
    "} \n",
    "\"\"\"\n",
    "\n",
    "input_data = {'statement': statement}\n",
    "\n",
    "result = exectue_sparql(input_data)\n",
    "\n",
    "json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "This demo illustrates a tool use scenario using Amazon Bedrock's Converse API and a tool to query SPRAQL.\n",
    "The script interacts with a foundation model on Amazon Bedrock and an in memory graph to provide location\n",
    "information based on user input.\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import logging\n",
    "from enum import Enum\n",
    "\n",
    "from classes import tool_use_print_utils as output\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(message)s\")\n",
    "\n",
    "\n",
    "\n",
    "# For the most recent list of models supported by the Converse API's tool use functionality, visit:\n",
    "# https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html\n",
    "class SupportedModels(Enum):\n",
    "    CLAUDE_SONNET = \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "    CLAUDE_SONNET_3_7 =  \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "\n",
    "\n",
    "# Set the model ID, e.g., Claude 3 Sonnet 3.7.\n",
    "MODEL_ID = SupportedModels.CLAUDE_SONNET_3_7.value\n",
    "\n",
    "# Define the system prompt with the instructions for the agent\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a location analysis assistant that provides location information for user-specified locations using only\n",
    "the Sparql_Tool, which expects a SPARQL select statement. The user is going to ask about a location.  \n",
    "\n",
    "Based on the rules generate a SPARQL SELECT statement for the location. Limit the SPARQL result set to a max of 100. \n",
    "Finally, use the Sparql_Tool to execute the SPARQL SELECT statement and return the results.  \n",
    "If the respons starts with \"No data found\" then tell the user that you were unable to find any results for that question and to ask a different question and STOP.\n",
    "\n",
    "Instructions:\n",
    "- Use only the node types and properties provided in the schema.\n",
    "- Do not use any node types and properties that are not explicitly provided.\n",
    "- Include all necessary prefixes.\n",
    "- Given any relationship property, you should just use them following the relationship paths provided, respecting the direction of the relationship path.\n",
    "\n",
    "The query should follow the following guidance:\n",
    "- Always generate the from clause using graph <https://terraframe.com/example/graph#>.\n",
    "```\n",
    "// Incorrect\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "PREFIX geo: <http://www.opengis.net/ont/geosparql#>\n",
    "\n",
    "SELECT DISTINCT ?schoolZoneName\n",
    "WHERE {\n",
    "    ?leveeArea obj:GeoObject-code \"LEV_A_229\" .\n",
    "    ?leveeArea obj:HasFloodZone ?leveedArea .\n",
    "    ?leveedArea obj:HasFloodRisk ?school .\n",
    "    ?schoolZone obj:HasSchoolZone ?school .\n",
    "    ?schoolZone rdfs:label ?schoolZoneName .\n",
    "\n",
    "// Correct\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "PREFIX geo: <http://www.opengis.net/ont/geosparql#>\n",
    "\n",
    "SELECT DISTINCT ?schoolZoneName\n",
    "FROM <https://terraframe.com/example/graph#>\n",
    "WHERE {\n",
    "    ?leveeArea obj:GeoObject-code \"LEV_A_229\" .\n",
    "    ?leveeArea obj:HasFloodZone ?leveedArea .\n",
    "    ?leveedArea obj:HasFloodRisk ?school .\n",
    "    ?schoolZone obj:HasSchoolZone ?school .\n",
    "    ?schoolZone rdfs:label ?schoolZoneName .\n",
    "}```\n",
    "\n",
    "- Self referencing should always generate an edge with *\n",
    "```\n",
    "// Incorrect\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "PREFIX geo: <http://www.opengis.net/ont/geosparql#>\n",
    "\n",
    "SELECT DISTINCT ?tractCode ?tractLabel\n",
    "FROM <https://terraframe.com/example/graph#>\n",
    "WHERE {     \n",
    "  ?parent rdf:type obj:ChannelReach ;\n",
    "  obj:GeoObject-code \"CEMVK_RR_03_ONE_27\" .     \n",
    "  ?parent obj:FlowsInto ?channel .     \n",
    "  ?channel obj:ChannelHasLevee ?leveeArea .     \n",
    "  ?leveeArea obj:GeoObject-code ?leveeAreaCode .     \n",
    "} \n",
    "\n",
    "// Correct\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "PREFIX geo: <http://www.opengis.net/ont/geosparql#>\n",
    "\n",
    "SELECT DISTINCT ?tractCode ?tractLabel\n",
    "FROM <https://terraframe.com/example/graph#>\n",
    "WHERE {     \n",
    "  ?parent rdf:type obj:ChannelReach ;\n",
    "  obj:GeoObject-code \"CEMVK_RR_03_ONE_27\" .     \n",
    "  ?parent obj:FlowsInto* ?channel .     \n",
    "  ?channel obj:ChannelHasLevee ?leveeArea .     \n",
    "  ?leveeArea obj:GeoObject-code ?leveeAreaCode .     \n",
    "}```\n",
    "- Aggregation functions must always be wrapped in parenthesis with its variable name\n",
    "```\n",
    "// Incorrect\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "\n",
    "SELECT SUM(?population) as ?totalPopulation\n",
    "FROM <https://terraframe.com/example/graph#>\n",
    "WHERE {\n",
    "  ?censusTract obj:GeoObject-code \"CEMVK_RR_03_ONE_27\" .\n",
    "  ?censusTract obj:CensusTract-population ?population .  \n",
    "} \n",
    "\n",
    "// Correct\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "\n",
    "SELECT (SUM(?population) as ?totalPopulation) \n",
    "FROM <https://terraframe.com/example/graph#>\n",
    "WHERE {\n",
    "  SELECT DISTINCT ?censusTract ?population\n",
    "  WHERE {      \n",
    "    ?censusTract obj:GeoObject-code \"CEMVK_RR_03_ONE_27\" .\n",
    "    ?censusTract obj:CensusTract-population ?population .  \n",
    "  }\n",
    "} ```\n",
    "- Aggregation functions must always restrict values their distinct subject\n",
    "```\n",
    "// Incorrect\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "\n",
    "SELECT (SUM(?population) as ?totalPopulation) \n",
    "FROM <https://terraframe.com/example/graph#>\n",
    "WHERE {\n",
    "  ?censusTract obj:GeoObject-code \"CEMVK_RR_03_ONE_27\" .\n",
    "  ?censusTract obj:CensusTract-population ?population .  \n",
    "} \n",
    "\n",
    "// Correct\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX obj: <https://terraframe.com/example/graph#>\n",
    "\n",
    "SELECT (SUM(?population) as ?totalPopulation) \n",
    "FROM <https://terraframe.com/example/graph#>\n",
    "WHERE {\n",
    "  SELECT DISTINCT ?censusTract ?population\n",
    "  WHERE {      \n",
    "    ?censusTract obj:GeoObject-code \"CEMVK_RR_03_ONE_27\" .\n",
    "    ?censusTract obj:CensusTract-population ?population .  \n",
    "  }\n",
    "} ```\n",
    "Note: Be as concise as possible.\n",
    "Do not include any explanations or apologies in your responses.\n",
    "Do not include any text except the SPARQL query generated.\n",
    "\n",
    "\n",
    "Schema:\n",
    "In the following, each IRI is followed by the local name and optionally its description in parentheses. \n",
    "The graph supports the following node types:\n",
    "\n",
    "<https://terraframe.com/example/graph#ChannelReach> (ChannelReach), \n",
    "<https://terraframe.com/example/graph#School> (School), \n",
    "<https://terraframe.com/example/graph#LeveeArea> (LeveeArea), \n",
    "<https://terraframe.com/example/graph#LeveedArea> (LeveedArea), \n",
    "<https://terraframe.com/example/graph#SchoolZone> (SchoolZone), \n",
    "<https://terraframe.com/example/graph#CensusTract> (CensusTract), \n",
    "\n",
    "The graph supports the following relationships:\n",
    "<http://www.w3.org/2000/01/rdf-schema#label> (label), \n",
    "<http://www.w3.org/1999/02/22-rdf-syntax-ns#type> (type), \n",
    "<https://terraframe.com/example/graph#code> (code), \n",
    "<https://terraframe.com/example/graph#School-population> (School-population), \n",
    "<https://terraframe.com/example/graph#CensusTract-population> (CensusTract-population), \n",
    "<https://terraframe.com/example/graph#FlowsInto> (FlowsInto), \n",
    "<https://terraframe.com/example/graph#ChannelHasLevee> (ChannelHasLevee), \n",
    "<https://terraframe.com/example/graph#HasFloodZone> (HasFloodZone), \n",
    "<https://terraframe.com/example/graph#HasSchoolZone> (HasSchoolZone), \n",
    "<https://terraframe.com/example/graph#TractAtRisk> (TractAtRisk), \n",
    "<https://terraframe.com/example/graph#HasFloodRisk> (HasFloodRisk), \n",
    "\n",
    "The data model between types is the following:\n",
    "(ChannelReach)-[FlowsInto]->(ChannelReach),\n",
    "(ChannelReach)-[ChannelHasLevee]->(LeveeArea),\n",
    "(LeveeArea)-[HasFloodZone]->(LeveedArea),\n",
    "(CensusTract)-[TractAtRisk]->(LeveedArea),\n",
    "(LeveedArea)-[HasFloodRisk]->(School),\n",
    "(SchoolZone)-[HasSchoolZone]->(School)\n",
    "\n",
    "If the user asks about population use CensusTract-population. If the user asks about the number of students use School-population.    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# The maximum number of recursive calls allowed in the tool_use_demo function.\n",
    "# This helps prevent infinite loops and potential performance issues.\n",
    "MAX_RECURSIONS = 5\n",
    "\n",
    "\n",
    "class GraphToolDemo:\n",
    "    \"\"\"\n",
    "    Demonstrates the tool use feature with the Amazon Bedrock Converse API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Prepare the system prompt\n",
    "        self.system_prompt = [{\"text\": SYSTEM_PROMPT}]\n",
    "\n",
    "        # Prepare the tool configuration with the sparql tool's specification\n",
    "        self.tool_config = {\"tools\": [get_tool_spec()]}\n",
    "\n",
    "        # Create a Bedrock Runtime client in the specified AWS Region.\n",
    "        self.bedrockRuntimeClient = boto3.client(\n",
    "            \"bedrock-runtime\", \n",
    "            region_name=os.getenv('AWS_REGION'),\n",
    "            aws_access_key_id=os.getenv('AWS_KEY_ID'),\n",
    "            aws_secret_access_key=os.getenv('AWS_SECRET_KEY')\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Starts the conversation with the user and handles the interaction with Bedrock.\n",
    "        \"\"\"\n",
    "        # Print the greeting and a short user guide\n",
    "        output.header()\n",
    "\n",
    "        # Start with an emtpy conversation\n",
    "        conversation = []\n",
    "\n",
    "        # Get the first user input\n",
    "        user_input = self._get_user_input()\n",
    "\n",
    "        while user_input is not None:\n",
    "            # Create a new message with the user input and append it to the conversation\n",
    "            message = {\"role\": \"user\", \"content\": [{\"text\": user_input}]}\n",
    "            conversation.append(message)\n",
    "\n",
    "            # Send the conversation to Amazon Bedrock\n",
    "            bedrock_response = self._send_conversation_to_bedrock(conversation)\n",
    "\n",
    "            # Recursively handle the model's response until the model has returned\n",
    "            # its final response or the recursion counter has reached 0\n",
    "            self._process_model_response(\n",
    "                bedrock_response, conversation, max_recursion=MAX_RECURSIONS\n",
    "            )\n",
    "\n",
    "            # Repeat the loop until the user decides to exit the application\n",
    "            user_input = self._get_user_input()\n",
    "\n",
    "        output.footer()\n",
    "\n",
    "    def _send_conversation_to_bedrock(self, conversation):\n",
    "        \"\"\"\n",
    "        Sends the conversation, the system prompt, and the tool spec to Amazon Bedrock, and returns the response.\n",
    "\n",
    "        :param conversation: The conversation history including the next message to send.\n",
    "        :return: The response from Amazon Bedrock.\n",
    "        \"\"\"\n",
    "        output.call_to_bedrock(conversation)\n",
    "\n",
    "        # Send the conversation, system prompt, and tool configuration, and return the response\n",
    "        return self.bedrockRuntimeClient.converse(\n",
    "            modelId=MODEL_ID,\n",
    "            messages=conversation,\n",
    "            system=self.system_prompt,\n",
    "            toolConfig=self.tool_config,\n",
    "        )\n",
    "\n",
    "    def _process_model_response(\n",
    "        self, model_response, conversation, max_recursion=MAX_RECURSIONS\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Processes the response received via Amazon Bedrock and performs the necessary actions\n",
    "        based on the stop reason.\n",
    "\n",
    "        :param model_response: The model's response returned via Amazon Bedrock.\n",
    "        :param conversation: The conversation history.\n",
    "        :param max_recursion: The maximum number of recursive calls allowed.\n",
    "        \"\"\"\n",
    "\n",
    "        if max_recursion <= 0:\n",
    "            # Stop the process, the number of recursive calls could indicate an infinite loop\n",
    "            logging.warning(\n",
    "                \"Warning: Maximum number of recursions reached. Please try again.\"\n",
    "            )\n",
    "            exit(1)\n",
    "\n",
    "        # Append the model's response to the ongoing conversation\n",
    "        message = model_response[\"output\"][\"message\"]\n",
    "        conversation.append(message)\n",
    "        \n",
    "        if model_response[\"stopReason\"] == \"tool_use\":\n",
    "            # If the stop reason is \"tool_use\", forward everything to the tool use handler\n",
    "            self._handle_tool_use(message, conversation, max_recursion)\n",
    "\n",
    "        if model_response[\"stopReason\"] == \"end_turn\":\n",
    "            # If the stop reason is \"end_turn\", print the model's response text, and finish the process\n",
    "            \n",
    "            if(len(message[\"content\"]) > 0) :\n",
    "                output.model_response(message[\"content\"][0][\"text\"])\n",
    "            else:\n",
    "                output.model_response(\"Agent returned an empty response\")\n",
    "\n",
    "            return\n",
    "\n",
    "    def _handle_tool_use(\n",
    "        self, model_response, conversation, max_recursion=MAX_RECURSIONS\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Handles the tool use case by invoking the specified tool and sending the tool's response back to Bedrock.\n",
    "        The tool response is appended to the conversation, and the conversation is sent back to Amazon Bedrock for further processing.\n",
    "\n",
    "        :param model_response: The model's response containing the tool use request.\n",
    "        :param conversation: The conversation history.\n",
    "        :param max_recursion: The maximum number of recursive calls allowed.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize an empty list of tool results\n",
    "        tool_results = []\n",
    "\n",
    "        # The model's response can consist of multiple content blocks\n",
    "        for content_block in model_response[\"content\"]:\n",
    "            if \"text\" in content_block:\n",
    "                # If the content block contains text, print it to the console\n",
    "                output.model_response(content_block[\"text\"])\n",
    "\n",
    "            if \"toolUse\" in content_block:\n",
    "                # If the content block is a tool use request, forward it to the tool\n",
    "                tool_response = self._invoke_tool(content_block[\"toolUse\"])\n",
    "\n",
    "                # Add the tool use ID and the tool's response to the list of results\n",
    "                tool_results.append(\n",
    "                    {\n",
    "                        \"toolResult\": {\n",
    "                            \"toolUseId\": (tool_response[\"toolUseId\"]),\n",
    "                            \"content\": [{\"json\": {'rows': tool_response[\"content\"]}}],\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "\n",
    "        # Embed the tool results in a new user message\n",
    "        message = {\"role\": \"user\", \"content\": tool_results}\n",
    "        \n",
    "        # Append the new message to the ongoing conversation\n",
    "        conversation.append(message)\n",
    "        \n",
    "        # Send the conversation to Amazon Bedrock\n",
    "        response = self._send_conversation_to_bedrock(conversation)\n",
    "        \n",
    "        # Recursively handle the model's response until the model has returned\n",
    "        # its final response or the recursion counter has reached 0\n",
    "        self._process_model_response(response, conversation, max_recursion - 1)\n",
    "\n",
    "    def _invoke_tool(self, payload):\n",
    "        \"\"\"\n",
    "        Invokes the specified tool with the given payload and returns the tool's response.\n",
    "        If the requested tool does not exist, an error message is returned.\n",
    "\n",
    "        :param payload: The payload containing the tool name and input data.\n",
    "        :return: The tool's response or an error message.\n",
    "        \"\"\"\n",
    "        tool_name = payload[\"name\"]\n",
    "\n",
    "        if tool_name == \"Sparql_Tool\":\n",
    "            input_data = payload[\"input\"]\n",
    "            output.tool_use(tool_name, input_data)\n",
    "\n",
    "            # Invoke the sparql tool with the input data provided by\n",
    "            response = exectue_sparql(input_data)\n",
    "        else:\n",
    "            error_message = (\n",
    "                f\"The requested tool with name '{tool_name}' does not exist.\"\n",
    "            )\n",
    "            response = {\"error\": \"true\", \"message\": error_message}\n",
    "\n",
    "        return {\"toolUseId\": payload[\"toolUseId\"], \"content\": response}\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_user_input(prompt=\"Your location info request\"):\n",
    "        \"\"\"\n",
    "        Prompts the user for input and returns the user's response.\n",
    "        Returns None if the user enters 'x' to exit.\n",
    "\n",
    "        :param prompt: The prompt to display to the user.\n",
    "        :return: The user's input or None if the user chooses to exit.\n",
    "        \"\"\"\n",
    "        output.separator()\n",
    "        user_input = input(f\"{prompt} (x to exit): \")\n",
    "\n",
    "        if user_input == \"\":\n",
    "            prompt = \"Please enter your location info request, e.g. the name of a location in the graph\"\n",
    "            return GraphToolDemo._get_user_input(prompt)\n",
    "\n",
    "        elif user_input.lower() == \"x\":\n",
    "            return None\n",
    "\n",
    "        else:\n",
    "            return user_input\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tool_use_demo = GraphToolDemo()\n",
    "    tool_use_demo.run()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
